{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Adjust\" data-toc-modified-id=\"Adjust-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Adjust</a></span><ul class=\"toc-item\"><li><span><a href=\"#estimar-comprimento-do-corpo-e-area-para-algumas-amostras\" data-toc-modified-id=\"estimar-comprimento-do-corpo-e-area-para-algumas-amostras-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>estimar comprimento do corpo e area para algumas amostras</a></span></li><li><span><a href=\"#baseado-na-area-e-comprimneto-de-trofalax,-selecionar-imagens-para-treinar-a-rede\" data-toc-modified-id=\"baseado-na-area-e-comprimneto-de-trofalax,-selecionar-imagens-para-treinar-a-rede-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>baseado na area e comprimneto de trofalax, selecionar imagens para treinar a rede</a></span></li><li><span><a href=\"#Passar-contornos-na-rede-a-cada-frame\" data-toc-modified-id=\"Passar-contornos-na-rede-a-cada-frame-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Passar contornos na rede a cada frame</a></span></li></ul></li><li><span><a href=\"#Create-prepare-data-to-train-mask-rcnn\" data-toc-modified-id=\"Create-prepare-data-to-train-mask-rcnn-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Create prepare data to train mask rcnn</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-multiple-random-backgrounds-from-NET\" data-toc-modified-id=\"Get-multiple-random-backgrounds-from-NET-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Get multiple random backgrounds from NET</a></span></li><li><span><a href=\"#Create-some-abstract-backgrounds\" data-toc-modified-id=\"Create-some-abstract-backgrounds-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Create some abstract backgrounds</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from numba import vectorize\n",
    "import imutils\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy import ndimage\n",
    "from utils.video_utils import blob_extractor\n",
    "from blob import Blob\n",
    "\n",
    "####################entries for user\n",
    "n_obj=6\n",
    "######\n",
    "\n",
    "I = np.zeros((100,700,3), np.uint8)\n",
    "\n",
    "videoPath = \"videos/bee_s_talco.mov\"\n",
    "# Create a video capture object to read videos\n",
    "cap = cv2.VideoCapture(videoPath)\n",
    "\n",
    "frame_n_tot = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.namedWindow('image',cv2.WINDOW_AUTOSIZE) # \n",
    "cv2.createTrackbar(\"Max\", \"image\",255,255,nothing)\n",
    "#cv2.setTrackbarPos('Max',\"image\", 255)\n",
    "\n",
    "cv2.createTrackbar(\"Limiar\", \"image\",95,255,nothing)\n",
    "#cv2.setTrackbarPos('Limiar',\"image\", 100)\n",
    "\n",
    "cv2.createTrackbar(\"Max area\", \"image\",1800,10000,nothing)\n",
    "#cv2.setTrackbarPos('Max area',\"image\", 1000)\n",
    "\n",
    "cv2.createTrackbar(\"Min area\", \"image\",25,10000,nothing)\n",
    "#cv2.setTrackbarPos('Min area',\"image\", 70)\n",
    "\n",
    "cv2.createTrackbar(\"Max Body len\", \"image\",220,2000,nothing)\n",
    "cv2.createTrackbar(\"Min Body len\", \"image\",5,2000,nothing)\n",
    "\n",
    "cv2.createTrackbar(\"Frame number\", 'image',0, int(frame_n_tot), nothing)\n",
    "cv2.setTrackbarPos('Frame number',\"image\", 0)\n",
    "\n",
    "# config plot histograma\n",
    "\n",
    "while(1):\n",
    "    #read the frame\n",
    "    actual_n_frame = cv2.getTrackbarPos(\"Frame number\", \"image\")\n",
    "    cap.set(1, actual_n_frame)\n",
    "    success, frame1 = cap.read()\n",
    "    \n",
    "    # quit if unable to read the video file\n",
    "\n",
    "    frame=frame1[0:2160, 0:2500,]\n",
    "    frame_desenho=frame.copy()\n",
    "\n",
    "    frame = cv2.resize(frame,( 640, 480))\n",
    "    frame_desenho = cv2.resize(frame_desenho,( 640, 480))\n",
    "    \n",
    "    #frame = imutils.resize(frame, width=1900)\n",
    "    #frame_desenho = imutils.resize(frame_desenho, width=1900)\n",
    "    \n",
    "    #frame = cv2.cvtColor(frame_n, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    if not success:\n",
    "      print('Failed to read video')\n",
    "      sys.exit(1)\n",
    "\n",
    "    ## Select boxes\n",
    "    bboxes = []\n",
    "    colors = []\n",
    "    bboxes_atual = []\n",
    "    list_bboxes_atual= []\n",
    "    pts_oculto = deque(maxlen=100)\n",
    "    pts = deque(maxlen=100)\n",
    "    #############################################################  \n",
    "   \n",
    "    gray = cv2.cvtColor(frame.copy(),cv2.COLOR_BGR2GRAY)\n",
    "    gray_nor=((gray.copy()/np.mean(gray)))\n",
    "\n",
    "    gray_nor=(gray_nor-gray_nor.min())/(gray_nor.max()-gray_nor.min())*255\n",
    "    gray_nor = np.uint8(gray_nor)\n",
    "\n",
    "    hu_Max=cv2.getTrackbarPos(\"Max\", \"image\")\n",
    "    hu_limiar=cv2.getTrackbarPos(\"Limiar\", \"image\")\n",
    "\n",
    "    ret, thresh = cv2.threshold(gray_nor,hu_limiar,hu_Max,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "        # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "\n",
    "        # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,0)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.3*dist_transform.max(),255,0)\n",
    "\n",
    "        # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #estimar comprimento do corpo    \n",
    "    segmentedFrame= sure_fg.copy()\n",
    "    # Fill holes in the segmented frame to avoid duplication of contours\n",
    "    segmentedFrame = ndimage.binary_fill_holes(segmentedFrame).astype('uint8')\n",
    "    frameGray=gray\n",
    "    \n",
    "    max_area =cv2.getTrackbarPos(\"Max area\", \"image\")\n",
    "    min_area =cv2.getTrackbarPos(\"Min area\", \"image\")\n",
    "    \n",
    "    max_body_len =cv2.getTrackbarPos(\"Max Body len\", \"image\")\n",
    "    min_body_len =cv2.getTrackbarPos(\"Min Body len\", \"image\") \n",
    "    \n",
    "    bounding_boxes, miniframes, centroids, \\\n",
    "            areas, pixels, contours, estimated_body_lengths, countours_got = blob_extractor(segmentedFrame,\n",
    "                                                                                            frameGray,\n",
    "                                                                                            min_area,\n",
    "                                                                                            max_area,\n",
    "                                                                                            min_body_len,\n",
    "                                                                                            max_body_len)  \n",
    "\n",
    "   \n",
    "\n",
    "    cv2.drawContours(frame_desenho, contours, -1, (0,0,255), -1)\n",
    "        \n",
    "    #ellipse = cv2.fitEllipse(contours)\n",
    "    #frame_desenho = cv2.ellipse(frame_desenho,ellipse,(0,255,0),2)\n",
    "        \n",
    "    \n",
    "    cv2.putText(frame_desenho, \"Min detected area: \" + str(min(areas)),\n",
    "                ( int((frame.shape[0]*1)/100) , int((frame.shape[0]*1.5)/100) ), cv2.FONT_HERSHEY_SIMPLEX, 0.4,(70,25,255),1)\n",
    "        cv2.putText(frame_desenho, \"Max detected area: \" + str(max(areas)),\n",
    "                ( int((frame.shape[0]*1)/100) , int((frame.shape[0]*3.5)/100) ), cv2.FONT_HERSHEY_SIMPLEX, 0.4,(70,25,255),1)\n",
    "    cv2.putText(frame_desenho, \"SD area: \" + str(round(np.std((areas)),2)),\n",
    "                ( int((frame.shape[0]*1)/100) , int((frame.shape[0]*5.5)/100) ), cv2.FONT_HERSHEY_SIMPLEX, 0.4,(70,25,255),1)\n",
    "    cv2.putText(frame_desenho, \"Median area: \" + str(np.median(areas)),\n",
    "                ( int((frame.shape[0]*1)/100) , int((frame.shape[0]*7.5)/100) ), cv2.FONT_HERSHEY_SIMPLEX, 0.4,(70,25,255),1)\n",
    "    \n",
    "    cv2.putText(frame_desenho, \"Min detected Body len: \" + str(min(estimated_body_lengths)),\n",
    "                (int((frame.shape[0]*1)/100),int((frame.shape[0]*9.5)/100)), cv2.FONT_HERSHEY_SIMPLEX, 0.4,(70,25,255),1)\n",
    "    cv2.putText(frame_desenho, \"Max detected Body len: \" + str(max(estimated_body_lengths)),\n",
    "                (int((frame.shape[0]*1)/100),int((frame.shape[0]*11.5)/100)), cv2.FONT_HERSHEY_SIMPLEX, 0.4,(70,25,255),1)\n",
    "    cv2.putText(frame_desenho, \"SD Body len: \" + str(round(np.std((estimated_body_lengths)),2)),\n",
    "                (int((frame.shape[0]*1)/100),int((frame.shape[0]*13.5)/100)), cv2.FONT_HERSHEY_SIMPLEX, 0.4,(70,25,255),1)    \n",
    "    cv2.putText(frame_desenho, \"Median Body len: \" + str(np.median(estimated_body_lengths)),\n",
    "                (int((frame.shape[0]*1)/100),int((frame.shape[0]*15.5)/100)), cv2.FONT_HERSHEY_SIMPLEX, 0.4,(70,25,255),1)\n",
    "            \n",
    "    \n",
    "    #cv2.imshow('image',I)\n",
    "    cv2.imshow('image',cv2.resize(I, (0,0), fx=0.9, fy=0.4))\n",
    "    cv2.imshow('teste',cv2.resize(frame_desenho, (0,0), fy= round(820/frame.shape[1],1), fx= round(580/frame.shape[0],1)))\n",
    "           \n",
    "        \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "    elif k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#plt.hist(gray.ravel(),256,[0,256]); plt.show()\n",
    "#plt.hist(gray_nor.ravel(),256,[0,256]); plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimar comprimento do corpo e area para algumas amostras\n",
    "\n",
    "Estimando nos frames onde não tem crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from utils.video_utils import blob_extractor\n",
    "from blob import Blob\n",
    "\n",
    "blobs_in_frame = []\n",
    "\n",
    "frame_identificator = []\n",
    "\n",
    "frame_n_act = 0\n",
    "\n",
    "videoPath = \"videos/bee_s_talco.mov\"\n",
    "# Create a video capture object to read videos\n",
    "cap = cv2.VideoCapture(videoPath)\n",
    "\n",
    "while frame_n_act <= 10:\n",
    "        \n",
    "    success, frame1 = cap.read()\n",
    "    \n",
    "    frame_n_act = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        \n",
    "    frame = frame1[0:2160, 0:2500,]    \n",
    "    frame_desenho = frame.copy()\n",
    "    frame = imutils.resize(frame, width=1900)\n",
    "    frame_desenho = imutils.resize(frame_desenho, width=1900)\n",
    "    #frame = cv2.cvtColor(frame_n, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    if not success:\n",
    "      print('Failed to read video')\n",
    "      sys.exit(1)\n",
    "         \n",
    "    gray = cv2.cvtColor(frame.copy(),cv2.COLOR_BGR2GRAY)\n",
    "    gray_nor=((gray.copy()/np.mean(gray)))\n",
    "\n",
    "    gray_nor=(gray_nor-gray_nor.min())/(gray_nor.max()-gray_nor.min())*255\n",
    "    gray_nor = np.uint8(gray_nor)   \n",
    "\n",
    "    ret, thresh = cv2.threshold(gray_nor,hu_limiar,hu_Max,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "        # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "\n",
    "        # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.3*dist_transform.max(),255,0)\n",
    "\n",
    "        # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    segmentedFrame= sure_fg.copy()\n",
    "    # Fill holes in the segmented frame to avoid duplication of contours\n",
    "    segmentedFrame = ndimage.binary_fill_holes(segmentedFrame).astype('uint8')\n",
    "\n",
    "    frameGray=gray\n",
    "\n",
    "    bounding_boxes, miniframes, centroids, \\\n",
    "            areas, pixels, contours, estimated_body_lengths, countours_got = blob_extractor(segmentedFrame,\n",
    "                                                                                            frameGray,\n",
    "                                                                                            min_area,\n",
    "                                                                                            max_area)\n",
    "           \n",
    "    if len(centroids)==6:\n",
    "        \n",
    "        for i, bounding_box in enumerate(bounding_boxes):\n",
    "            blob = Blob(centroids[i],\n",
    "                        contours[i],\n",
    "                        areas[i],\n",
    "                        bounding_box,\n",
    "                        bounding_box_image = miniframes[i],\n",
    "                        estimated_body_length = estimated_body_lengths[i],\n",
    "                        pixels = pixels[i],\n",
    "                        #countours_got=countours_got[i],\n",
    "                        number_of_animals = n_obj)\n",
    "            blobs_in_frame.append(blob)\n",
    "            frame_identificator.append(int(frame_n_act))           \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Body len median for trofalax:  216.0\n",
      "Body len min for trofalax:  131.84407933813793\n",
      "Body len max for trofalax:  300.15592066186207\n",
      "Body area median for trofalax:  4409.0\n",
      "Body area min for trofalax:  1220.7209526722504\n",
      "Body area max for trofalax:  7597.279047327749\n"
     ]
    }
   ],
   "source": [
    "estimated_body_len=[]\n",
    "estimared_body_area=[]\n",
    "for i in range (0,len(blobs_in_frame)):\n",
    "    estimated_body_len.append(blobs_in_frame[i].estimated_body_length)\n",
    "    estimared_body_area.append(blobs_in_frame[i].area)\n",
    "    \n",
    "#comprinto do corpo\n",
    "\n",
    "two_ind_body_len = 2*np.median(estimated_body_len)\n",
    "print(\"Body len median for trofalax: \",two_ind_body_len)\n",
    "minimo_body_len=two_ind_body_len- (2*np.std(estimated_body_len))\n",
    "maximo_body_len=two_ind_body_len+ (2*np.std(estimated_body_len))\n",
    "print(\"Body len min for trofalax: \",minimo_body_len)\n",
    "print(\"Body len max for trofalax: \",maximo_body_len)\n",
    "\n",
    "#area\n",
    "\n",
    "two_ind_body_area = 2*np.median(estimared_body_area)\n",
    "print(\"Body area median for trofalax: \",two_ind_body_area)\n",
    "minimo_two_ind_body_area = two_ind_body_area- 2*(np.std(estimared_body_area))\n",
    "maximo_two_ind_body_area = two_ind_body_area+ 2*(np.std(estimared_body_area))\n",
    "print(\"Body area min for trofalax: \", minimo_two_ind_body_area)\n",
    "print(\"Body area max for trofalax: \",maximo_two_ind_body_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseado na area e comprimneto de trofalax, selecionar imagens para treinar a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from utils.video_utils import blob_extractor\n",
    "from blob import Blob\n",
    "import random\n",
    "import os\n",
    "\n",
    "blobs_in_frame = []\n",
    "max_number_of_blobs = 0\n",
    "\n",
    "\n",
    "frame_identificator = []\n",
    "\n",
    "frame_n_act = 0\n",
    "\n",
    "videoPath = \"videos/bee_s_talco.mov\"\n",
    "# Create a video capture object to read videos\n",
    "cap = cv2.VideoCapture(videoPath)\n",
    "\n",
    "counter=0\n",
    "trofalax_countours=[]\n",
    "non_trofalax_countours=[]\n",
    "frames_amostrados = random.sample(range(int(frame_n_tot)), int(frame_n_tot))\n",
    "\n",
    "if not os.path.exists('./train_images/trofalax/'):\n",
    "    os.makedirs('./train_images/trofalax/')\n",
    "    \n",
    "if not os.path.exists('./train_images/non_trofalax/'):\n",
    "    os.makedirs('./train_images/non_trofalax/')  \n",
    "\n",
    "cap.set(1, 1803)\n",
    "while counter <= int(frame_n_tot):\n",
    "    \n",
    "    if len(trofalax_countours) >= 120:\n",
    "        break\n",
    "    \n",
    "    cap.set(1, frames_amostrados[counter])\n",
    "    success, frame1 = cap.read()\n",
    "    \n",
    "    #frame_n_act = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        \n",
    "    frame = frame1[0:2160, 0:2500,]    \n",
    "    frame_desenho = frame.copy()\n",
    "    frame = imutils.resize(frame, width=1900)\n",
    "    frame_desenho = imutils.resize(frame_desenho, width=1900)\n",
    "    #frame = cv2.cvtColor(frame_n, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    if not success:\n",
    "      print('Failed to read video')\n",
    "      sys.exit(1)\n",
    "         \n",
    "    counter+=1\n",
    "    \n",
    "    gray = cv2.cvtColor(frame.copy(),cv2.COLOR_BGR2GRAY)\n",
    "    gray_nor=((gray.copy()/np.mean(gray)))\n",
    "\n",
    "    gray_nor=(gray_nor-gray_nor.min())/(gray_nor.max()-gray_nor.min())*255\n",
    "    gray_nor = np.uint8(gray_nor)   \n",
    "\n",
    "    ret, thresh = cv2.threshold(gray_nor,hu_limiar,hu_Max,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "        # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "\n",
    "        # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.3*dist_transform.max(),255,0)\n",
    "\n",
    "        # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    segmentedFrame= sure_fg.copy()\n",
    "    # Fill holes in the segmented frame to avoid duplication of contours\n",
    "    segmentedFrame = ndimage.binary_fill_holes(segmentedFrame).astype('uint8')\n",
    "\n",
    "    frameGray=gray\n",
    "\n",
    "    bounding_boxes, miniframes, centroids, \\\n",
    "            areas, pixels, contours, estimated_body_lengths, countours_got = blob_extractor(segmentedFrame,\n",
    "                                                                                            frameGray,\n",
    "                                                                                            min_area,\n",
    "                                                                                            max_area)\n",
    "    \n",
    "    max_number_of_blobs=1\n",
    "    \n",
    "    if len(centroids)>1 and len(centroids) < 6:\n",
    "        \n",
    "        for i, bounding_box in enumerate(bounding_boxes):\n",
    "            blob = Blob(centroids[i],\n",
    "                        contours[i],\n",
    "                        areas[i],\n",
    "                        bounding_box,\n",
    "                        bounding_box_image = miniframes[i],\n",
    "                        estimated_body_length = estimated_body_lengths[i],\n",
    "                        pixels = pixels[i],\n",
    "                        #countours_got=countours_got[i],\n",
    "                        number_of_animals = n_obj)\n",
    "            \n",
    "            if estimated_body_lengths[i] >= minimo_body_len and estimated_body_lengths[i] <= maximo_body_len and areas[i] >= minimo_two_ind_body_area and areas[i] <= maximo_two_ind_body_area:\n",
    "                          \n",
    "                cv2.imwrite('./train_images/trofalax_rest/' +str(counter)+'.png', miniframes[i])\n",
    "                trofalax_countours.append(contours[i])\n",
    "            #else:\n",
    "                #if len(non_trofalax_countours) < 200:\n",
    "                 #   cv2.imwrite('./train_images/non_trofalax/' +str(counter)+'.png', miniframes[i])\n",
    "                   # non_trofalax_countours.append(contours[i])\n",
    "            \n",
    "            blobs_in_frame.append(blob)\n",
    "            frame_identificator.append(int(frame_n_act))\n",
    "            \n",
    "        if len(centroids) > max_number_of_blobs:\n",
    "            max_number_of_blobs = len(centroids)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( trofalax_countours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passar contornos na rede a cada frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from utils.video_utils import blob_extractor\n",
    "from blob import Blob\n",
    "import random\n",
    "import os\n",
    "\n",
    "blobs_in_frame = []\n",
    "max_number_of_blobs = 0\n",
    "\n",
    "\n",
    "frame_identificator = []\n",
    "\n",
    "frame_n_act = 0\n",
    "\n",
    "videoPath = \"videos/bee_s_talco.mov\"\n",
    "# Create a video capture object to read videos\n",
    "cap = cv2.VideoCapture(videoPath)\n",
    "\n",
    "counter=0\n",
    "trofalax_countours=[]\n",
    "non_trofalax_countours=[]\n",
    "\n",
    "while counter <= int(frame_n_tot):\n",
    "    \n",
    "    if len(trofalax_countours) >= 120:\n",
    "        break\n",
    "    \n",
    "    success, frame1 = cap.read()\n",
    "      \n",
    "        \n",
    "    frame = frame1[0:2160, 0:2500,]    \n",
    "    frame_desenho = frame.copy()\n",
    "    frame = imutils.resize(frame, width=1900)\n",
    "    frame_desenho = imutils.resize(frame_desenho, width=1900)\n",
    "    #frame = cv2.cvtColor(frame_n, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    if not success:\n",
    "      print('Failed to read video')\n",
    "      sys.exit(1)\n",
    "         \n",
    "    counter+=1\n",
    "    \n",
    "    gray = cv2.cvtColor(frame.copy(),cv2.COLOR_BGR2GRAY)\n",
    "    gray_nor=((gray.copy()/np.mean(gray)))\n",
    "\n",
    "    gray_nor=(gray_nor-gray_nor.min())/(gray_nor.max()-gray_nor.min())*255\n",
    "    gray_nor = np.uint8(gray_nor)   \n",
    "\n",
    "    ret, thresh = cv2.threshold(gray_nor,hu_limiar,hu_Max,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "        # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "\n",
    "        # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.3*dist_transform.max(),255,0)\n",
    "\n",
    "        # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    segmentedFrame= sure_fg.copy()\n",
    "    # Fill holes in the segmented frame to avoid duplication of contours\n",
    "    segmentedFrame = ndimage.binary_fill_holes(segmentedFrame).astype('uint8')\n",
    "\n",
    "    frameGray=gray\n",
    "\n",
    "    bounding_boxes, miniframes, centroids, \\\n",
    "            areas, pixels, contours, estimated_body_lengths, countours_got = blob_extractor(segmentedFrame,\n",
    "                                                                                            frameGray,\n",
    "                                                                                            min_area,\n",
    "                                                                                            max_area)\n",
    "    \n",
    "    max_number_of_blobs=1\n",
    "    \n",
    "    if len(centroids)>1 and len(centroids) < 6:\n",
    "        \n",
    "        for i in range (0, len(contours)):\n",
    "            #obter 0 ou 1 = passar miniframes[i] na rede\n",
    "            \n",
    "        \n",
    "        for i, bounding_box in enumerate(bounding_boxes):\n",
    "            blob = Blob(centroids[i],\n",
    "                        contours[i],\n",
    "                        areas[i],\n",
    "                        bounding_box,\n",
    "                        bounding_box_image = miniframes[i],\n",
    "                        estimated_body_length = estimated_body_lengths[i],\n",
    "                        pixels = pixels[i],\n",
    "                        #countours_got=countours_got[i],\n",
    "                        number_of_animals = n_obj)\n",
    "            \n",
    "            if estimated_body_lengths[i] >= minimo_body_len and estimated_body_lengths[i] <= maximo_body_len and areas[i] >= minimo_two_ind_body_area and areas[i] <= maximo_two_ind_body_area:\n",
    "                          \n",
    "                cv2.imwrite('./train_images/trofalax_rest/' +str(counter)+'.png', miniframes[i])\n",
    "                trofalax_countours.append(contours[i])\n",
    "            #else:\n",
    "                #if len(non_trofalax_countours) < 200:\n",
    "                 #   cv2.imwrite('./train_images/non_trofalax/' +str(counter)+'.png', miniframes[i])\n",
    "                   # non_trofalax_countours.append(contours[i])\n",
    "            \n",
    "            blobs_in_frame.append(blob)\n",
    "            frame_identificator.append(int(frame_n_act))\n",
    "            \n",
    "        if len(centroids) > max_number_of_blobs:\n",
    "            max_number_of_blobs = len(centroids)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "frament_id = [None] * len(blobs_in_frame)\n",
    "all_intersection=[]\n",
    "count = 0\n",
    "for j in range (0, len(blobs_in_frame)):\n",
    "    #if frament_id[j] is None:\n",
    "    for i in range (0, len(blobs_in_frame)):\n",
    "        if frament_id[i] is None:\n",
    "            intersection = np.intersect1d(blobs_in_frame[j].pixels, blobs_in_frame[i].pixels)\n",
    "            #all_intersection.append(len(intersection))\n",
    "            if len(intersection) > 0:\n",
    "                if frament_id[j] is not None:\n",
    "                    frament_id[i] = frament_id[j]\n",
    "                else:\n",
    "                    frament_id[i] = count\n",
    "    \n",
    "    count +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 2, 4, 5, 0, 1, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 1, 0, 2, 2, 4, 5, 0, 1, 2, 2, 4, 5, 0, 1, 2, 2, 4, 5, 0, 1, 2, 2, 4, 5, 0, 1, 2, 2, 4, 5, 0, 1, 2, 2, 4, 5, 0, 2, 2, 189, 190, 191, 0, 2, 2, 189, 190, 191, 0, 2, 2, 189, 190, 191, 0, 2, 206, 2, 3, 209, 0, 206, 2, 2, 3, 209, 0, 206, 2, 2, 3, 209]\n"
     ]
    }
   ],
   "source": [
    "print(frament_id)\n",
    "#print(frame_identificator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "280\n",
      "560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.607142857142858"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(blobs_in_frame[j].pixels))\n",
    "print(len(blobs_in_frame[i].pixels))\n",
    "print(len(blobs_in_frame[j].pixels)+len(blobs_in_frame[i].pixels))\n",
    "(len(intersection)/(len(blobs_in_frame[j].pixels)+len(blobs_in_frame[i].pixels)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n"
     ]
    }
   ],
   "source": [
    "maximo=[]\n",
    "indices=list(set(frament_id))\n",
    "\n",
    "for i in (set(frament_id)):    \n",
    "    maximo.append(frament_id.count(i))\n",
    "    \n",
    "for i in range (0, len(indices)):\n",
    "    if min(maximo)== maximo[i]:\n",
    "        print(indices[i])\n",
    "        mas_frag_number = indices[i]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "quase_final_id=[]\n",
    "grab_images=[]\n",
    "\n",
    "for i in range (0, len(frament_id)):\n",
    "    if frament_id[i] == mas_frag_number:\n",
    "        grab_ident = frame_identificator[i]\n",
    "        for j in range (0, len(frament_id)):\n",
    "            if grab_ident == frame_identificator[j]:\n",
    "                quase_final_id.append(frament_id[j])\n",
    "                grab_images.append(blobs_in_frame[j].bounding_box_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 206, 209]\n",
      "[0, 2, 206, 2, 3, 209, 0, 206, 2, 2, 3, 209, 0, 206, 2, 2, 3, 209]\n"
     ]
    }
   ],
   "source": [
    "indices_finais=list(set(quase_final_id))\n",
    "print(indices_finais)\n",
    "print(quase_final_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "indices_finais=list(set(quase_final_id))\n",
    "\n",
    "for j in (indices_finais):\n",
    "    for i in range(0, len(quase_final_id)):\n",
    "        if int(j) == int(quase_final_id[i]):\n",
    "            \n",
    "            \n",
    "            if not os.path.exists('./train_images/' +str(j)):\n",
    "                os.makedirs('./train_images/' +str(j))            \n",
    "            cv2.imwrite('./train_images/' +str(j)+'/'+str(i)+'.png', grab_images[i])        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create prepare data to train mask rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranoiu com cachorro -- https://hackernoon.com/instance-segmentation-in-google-colab-with-custom-dataset-b3099ac23f35\n",
    "# crear coco dataset -- http://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get multiple random backgrounds from NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_images_download import google_images_download\n",
    "\n",
    "\n",
    "response = google_images_download.googleimagesdownload()\n",
    "\n",
    "arguments = {\"keywords\":\"solo argila caly soil background leaves grass corn grain color gray blue pink burlap bush stored wood grain desert sand concrete cement\",\n",
    "             \"limit\":50,\"print_urls\":False,\n",
    "             \"output_directory\":\"mask_imgs\" ,\n",
    "             \"no_directory\": \"mask_imgs\", format: \"jpg\"}   #creating list of arguments\n",
    "\n",
    "paths = response.download(arguments)   #passing the arguments to the function\n",
    "print(paths) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some abstract backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,34):\n",
    "    out = cv2.imread(\"mask_imgs/1 (\" + str(i) +\")\" + \".jpg\")\n",
    "\n",
    "    linhas,colunas = out.shape[:2]\n",
    "\n",
    "    M = np.float32([[2,0,0],[0,2,0]])\n",
    "    out = cv2.warpAffine(out, M, (np.int(out.shape[0]/4), np.int(out.shape[1]/4)))\n",
    "\n",
    "\n",
    "    out = cv2.resize(out,( 640, 480))\n",
    "    \n",
    "    cv2.imwrite(\"mask_imgs/1 (\" + str(i+33) +\")\" + \".jpg\", out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Amostrar contornos para colocar nos backgounds**\n",
    "- **colocar os contornos amostrados nos backgounds**\n",
    "- **Salvar as imgs com contornos e arquivo json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "from utils.video_utils import blob_extractor\n",
    "from blob import Blob\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "frame_identificator = []\n",
    "\n",
    "frame_n_act = 0\n",
    "\n",
    "\n",
    "videoPath = \"videos/bee_s_talco.mov\"\n",
    "# Create a video capture object to read videos\n",
    "cap = cv2.VideoCapture(videoPath)\n",
    "\n",
    "frames_amostrados = random.sample(range(int(frame_n_tot)), 44)\n",
    "counter=0\n",
    "countours_amostrados=[]\n",
    "\n",
    "listas=[]\n",
    "\n",
    "while counter < 44:       \n",
    "    \n",
    "    cap.set(1, frames_amostrados[counter])\n",
    "        \n",
    "    success, frame1 = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        print('Failed to read video')\n",
    "        sys.exit(1)\n",
    "    \n",
    "            \n",
    "    frame = frame1[0:2160, 0:2500,]    \n",
    "    frame_desenho = frame.copy()\n",
    "    frame = cv2.resize(frame,( 640, 480))\n",
    "    frame_desenho = cv2.resize(frame_desenho,( 640, 480))\n",
    "            \n",
    "    gray = cv2.cvtColor(frame.copy(),cv2.COLOR_BGR2GRAY)\n",
    "    gray_nor=((gray.copy()/np.mean(gray)))\n",
    "\n",
    "    gray_nor=(gray_nor-gray_nor.min())/(gray_nor.max()-gray_nor.min())*255\n",
    "    gray_nor = np.uint8(gray_nor)   \n",
    "\n",
    "    ret, thresh = cv2.threshold(gray_nor,hu_limiar,hu_Max,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "        # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "\n",
    "        # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.3*dist_transform.max(),255,0)\n",
    "\n",
    "        # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    segmentedFrame= sure_fg.copy()\n",
    "    # Fill holes in the segmented frame to avoid duplication of contours\n",
    "    segmentedFrame = ndimage.binary_fill_holes(segmentedFrame).astype('uint8')\n",
    "\n",
    "    frameGray=gray\n",
    "\n",
    "    bounding_boxes, miniframes, centroids, \\\n",
    "            areas, pixels, contours, estimated_body_lengths, countours_got = blob_extractor(segmentedFrame,\n",
    "                                                                                            frameGray,\n",
    "                                                                                            min_area,\n",
    "                                                                                            max_area,\n",
    "                                                                                            min_body_len,\n",
    "                                                                                            max_body_len)\n",
    "    #countours_amostrados.append(contours)  \n",
    "       \n",
    "    out = cv2.imread(\"mask_imgs/1 (\" + str(counter+1) +\")\" + \".jpg\")\n",
    "\n",
    "    out = cv2.resize(out,( frame.shape[1], frame.shape[0])) \n",
    "\n",
    "    mask = np.zeros_like(frame) # Create mask where white is what we want, black otherwise\n",
    "    cv2.drawContours(mask, contours, -1, (255,255,255), -1) # Draw filled contour in mask\n",
    "\n",
    "    out[mask == (255,255,255)] = frame [mask == (255,255,255)]\n",
    "    \n",
    "    #out = cv2.resize(out,( 640, 480))\n",
    "    \n",
    "    cv2.imwrite(\"train/\" + str(counter+1) + \".jpg\", out)\n",
    "    \n",
    "    regions_acumulada=[]\n",
    "    for k in range (0,len(contours)):\n",
    "        \n",
    "        contornos_especifico = contours[k]\n",
    "\n",
    "        y = [j[0,1] for j in contornos_especifico] \n",
    "        x = [j[0,0] for j in contornos_especifico] \n",
    "\n",
    "        regions={str(k):{\"shape_attributes\":{\"name\":\"polygon\",\n",
    "                                             \"all_points_x\":x,\n",
    "                                             \"all_points_y\":y},\n",
    "                         \"region_attributes\":{}}}\n",
    "        \n",
    "        if regions[str(k)] is None:\n",
    "            pass\n",
    "            \n",
    "        else:            \n",
    "            regions_acumulada.append(regions)\n",
    "        \n",
    "    regions_acumulada_dicionario=regions_acumulada[0]\n",
    "    for t in range(1,len(regions_acumulada)):\n",
    "        regions_acumulada_dicionario.update(regions_acumulada[t])\n",
    "    \n",
    "    \n",
    "    annotation={\n",
    "    str(counter+1) + \".jpg\" + str(int(np.prod(out.shape[:3]))) :{\"fileref\":\"\",\n",
    "                         \"size\":int(np.prod(out.shape[:3])),\n",
    "                         \"filename\":str(counter+1) + \".jpg\",\n",
    "                         \"base64_img_data\":\"\",\n",
    "                         \"file_attributes\":{},\n",
    "                         \"regions\":regions_acumulada_dicionario}}\n",
    "    \n",
    "    \n",
    "    counter+=1\n",
    "    \n",
    "    listas.append(annotation)\n",
    "    \n",
    "    listas_dicionario=listas[0]\n",
    "    for g in range(1,len(listas)):\n",
    "        listas_dicionario.update(listas[g])\n",
    "    \n",
    "    \n",
    "        \n",
    "df = pd.DataFrame(listas_dicionario)\n",
    "df.to_json(path_or_buf='train/via_region_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the files in drive and train mask rcnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
