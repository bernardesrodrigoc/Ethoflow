{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rodrigo/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "#from keras.constraints import maxnorm\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "#from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from os import listdir\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "import os\n",
    "\n",
    "#matrix confusion\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  False\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1s (y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "        return recall\n",
    "   \n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inicialmente\n",
    "\n",
    "inspeção e pre processamnto nos dados\n",
    "\n",
    "avaliei as correlções em busca de multicoliariade\n",
    "\n",
    "e pca para verificar a importancia das variaveis.\n",
    "\n",
    "Mantive todas as variaveisriveis\n",
    "\n",
    "Os valores faltantes eu preenchi com a media do coluna.\n",
    "\n",
    "então padronizei os dados subtraindo da media e dividindo pelo desvio padrão (em cada variavel). \n",
    "\n",
    "isso evita efeito de escala\n",
    "\n",
    "dividio os dados com 75% para treinamento\n",
    "\n",
    "o modelo  foi \n",
    "\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dense(64, activation= 'relu'))  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "testei com diferentes arquiteturas e optando por modelo mais parcimonioso\n",
    "\n",
    "saida sigmoide pois é uma classificação biaria. \n",
    "\n",
    "utilizei optimizer por descida de gradiente  (SGD(learning_rate=0.00013,momentum=0.86),\n",
    "              loss='binary_crossentropy',metrics=['acc',f1])\n",
    "\n",
    "durante treinamnto a a acuracia da validação foi avaliada e se não melhorasse em 15 epoca consecutivas parava\n",
    "\n",
    "tamano do lote foi 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5    16\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_fwf('data/entradasclassalunos.txt', sep=\" \", header=None)\n",
    "labels = pd.read_fwf('data/saidaclassalunos.txt', sep=\" \", header=None)\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n",
    "##### jogando na pra media\n",
    "def fillWithMean(df):\n",
    "    return df.fillna(df.mean()).dropna(axis=1, how='all') # funcao muito boa para remover outlier e jogar pra media da coluna\n",
    "\n",
    "data=fillWithMean(data)\n",
    "\n",
    "#### jogando retirando coluna com na\n",
    "\n",
    "#data=pd.DataFrame.dropna(data, axis=1, how='any')\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = data.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "data = pd.DataFrame(x_scaled)\n",
    "\n",
    "labels.head()\n",
    "\n",
    "data = np.array(data, dtype=\"float\") \n",
    "labels = np.array(labels)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels_strat= lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75000, saving model to model_2.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.75000 to 0.78378, saving model to model_2.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.78378 to 0.80405, saving model to model_2.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.80405 to 0.83784, saving model to model_2.h5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.83784 to 0.87162, saving model to model_2.h5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.87162 to 0.89865, saving model to model_2.h5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.89865 to 0.91892, saving model to model_2.h5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91892 to 0.93243, saving model to model_2.h5\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93243\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93243\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.93243 to 0.93919, saving model to model_2.h5\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93919\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93919\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93919\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93919\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93919\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93919\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93919\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.93919 to 0.95946, saving model to model_2.h5\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.95946\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.95946 to 0.96622, saving model to model_2.h5\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.96622\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.96622\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.96622 to 0.97973, saving model to model_2.h5\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.97973\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.97973\n",
      "Epoch 00039: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(testX, trainX, testY, trainY) = train_test_split(data, labels,\n",
    "                                                  test_size=0.75, stratify= labels_strat, random_state=10)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "activationion= 'relu'\n",
    "\n",
    "model.add(Dense(128, activation= activationion))\n",
    "model.add(Dense(128, activation= activationion))\n",
    "model.add(Dense(64, activation= activationion))\n",
    "\n",
    "\n",
    "  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "  #model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "model.compile(optimizer=SGD(learning_rate=0.000134,momentum=0.864)  , loss='binary_crossentropy',metrics=['acc',f1])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_2.h5\", monitor='val_acc', verbose=1, save_best_only=True,\n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "\n",
    "#H = model.fit(trainX, trainY, batch_size=4, validation_data=(testX, testY),\n",
    " #                       epochs = 50, verbose=1 ,callbacks =[checkpoint, early])\n",
    "\n",
    "history = model.fit(trainX, trainY, epochs=100, batch_size=5, validation_data=(testX, testY),callbacks =[checkpoint,early],verbose=0)  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['acc']\n",
    "val_loss_values = history_dict['val_acc']\n",
    "epochs = range(1, len(history_dict['val_acc']) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training acc') # 'bo' is for blue dot.\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation acc') # 'b' is for solid blue line\n",
    "plt.title('Training and validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 476 samples, validate on 119 samples\n",
      "Epoch 1/10\n",
      "476/476 [==============================] - 0s 637us/step - loss: 0.3687 - acc: 0.9118 - val_loss: 0.1701 - val_acc: 0.9748\n",
      "Epoch 2/10\n",
      "476/476 [==============================] - 0s 271us/step - loss: 0.1365 - acc: 0.9538 - val_loss: 0.1011 - val_acc: 0.9748\n",
      "Epoch 3/10\n",
      "476/476 [==============================] - 0s 246us/step - loss: 0.1118 - acc: 0.9622 - val_loss: 0.0987 - val_acc: 0.9664\n",
      "Epoch 4/10\n",
      "476/476 [==============================] - 0s 271us/step - loss: 0.1096 - acc: 0.9664 - val_loss: 0.0957 - val_acc: 0.9664\n",
      "Epoch 5/10\n",
      "476/476 [==============================] - 0s 242us/step - loss: 0.0954 - acc: 0.9643 - val_loss: 0.0887 - val_acc: 0.9832\n",
      "Epoch 6/10\n",
      "476/476 [==============================] - 0s 244us/step - loss: 0.0995 - acc: 0.9643 - val_loss: 0.1036 - val_acc: 0.9580\n",
      "Epoch 7/10\n",
      "476/476 [==============================] - 0s 243us/step - loss: 0.0936 - acc: 0.9706 - val_loss: 0.0974 - val_acc: 0.9664\n",
      "Epoch 8/10\n",
      "476/476 [==============================] - 0s 245us/step - loss: 0.0959 - acc: 0.9706 - val_loss: 0.0893 - val_acc: 0.9832\n",
      "Epoch 9/10\n",
      "476/476 [==============================] - 0s 245us/step - loss: 0.0779 - acc: 0.9748 - val_loss: 0.0888 - val_acc: 0.9832\n",
      "Epoch 10/10\n",
      "476/476 [==============================] - 0s 216us/step - loss: 0.0949 - acc: 0.9664 - val_loss: 0.0883 - val_acc: 0.9748\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 476 samples, validate on 119 samples\n",
      "Epoch 1/100\n",
      "460/476 [===========================>..] - ETA: 0s - loss: 0.6909 - acc: 0.6261\n",
      "Epoch 00001: val_acc improved from -inf to 0.66387, saving model to model_1.h5\n",
      "476/476 [==============================] - 1s 1ms/sample - loss: 0.6905 - acc: 0.6282 - val_loss: 0.6825 - val_acc: 0.6639\n",
      "Epoch 2/100\n",
      "384/476 [=======================>......] - ETA: 0s - loss: 0.6791 - acc: 0.6458\n",
      "Epoch 00002: val_acc did not improve from 0.66387\n",
      "476/476 [==============================] - 0s 333us/sample - loss: 0.6783 - acc: 0.6387 - val_loss: 0.6695 - val_acc: 0.6555\n",
      "Epoch 3/100\n",
      "444/476 [==========================>...] - ETA: 0s - loss: 0.6655 - acc: 0.6329\n",
      "Epoch 00003: val_acc improved from 0.66387 to 0.67227, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 301us/sample - loss: 0.6652 - acc: 0.6345 - val_loss: 0.6569 - val_acc: 0.6723\n",
      "Epoch 4/100\n",
      "420/476 [=========================>....] - ETA: 0s - loss: 0.6545 - acc: 0.6476\n",
      "Epoch 00004: val_acc improved from 0.67227 to 0.68908, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 323us/sample - loss: 0.6530 - acc: 0.6513 - val_loss: 0.6454 - val_acc: 0.6891\n",
      "Epoch 5/100\n",
      "444/476 [==========================>...] - ETA: 0s - loss: 0.6428 - acc: 0.6577\n",
      "Epoch 00005: val_acc improved from 0.68908 to 0.69748, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 298us/sample - loss: 0.6417 - acc: 0.6597 - val_loss: 0.6344 - val_acc: 0.6975\n",
      "Epoch 6/100\n",
      "236/476 [=============>................] - ETA: 0s - loss: 0.6380 - acc: 0.6525\n",
      "Epoch 00006: val_acc improved from 0.69748 to 0.70588, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 280us/sample - loss: 0.6307 - acc: 0.6723 - val_loss: 0.6235 - val_acc: 0.7059\n",
      "Epoch 7/100\n",
      "464/476 [============================>.] - ETA: 0s - loss: 0.6207 - acc: 0.6983\n",
      "Epoch 00007: val_acc improved from 0.70588 to 0.73950, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 289us/sample - loss: 0.6197 - acc: 0.7038 - val_loss: 0.6126 - val_acc: 0.7395\n",
      "Epoch 8/100\n",
      "256/476 [===============>..............] - ETA: 0s - loss: 0.6076 - acc: 0.7344\n",
      "Epoch 00008: val_acc improved from 0.73950 to 0.75630, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 251us/sample - loss: 0.6087 - acc: 0.7143 - val_loss: 0.6015 - val_acc: 0.7563\n",
      "Epoch 9/100\n",
      "224/476 [=============>................] - ETA: 0s - loss: 0.6012 - acc: 0.7321\n",
      "Epoch 00009: val_acc improved from 0.75630 to 0.79832, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 265us/sample - loss: 0.5974 - acc: 0.7416 - val_loss: 0.5900 - val_acc: 0.7983\n",
      "Epoch 10/100\n",
      "252/476 [==============>...............] - ETA: 0s - loss: 0.5909 - acc: 0.7460\n",
      "Epoch 00010: val_acc did not improve from 0.79832\n",
      "476/476 [==============================] - 0s 249us/sample - loss: 0.5856 - acc: 0.7815 - val_loss: 0.5780 - val_acc: 0.7983\n",
      "Epoch 11/100\n",
      "464/476 [============================>.] - ETA: 0s - loss: 0.5730 - acc: 0.8254\n",
      "Epoch 00011: val_acc improved from 0.79832 to 0.83193, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 288us/sample - loss: 0.5730 - acc: 0.8256 - val_loss: 0.5652 - val_acc: 0.8319\n",
      "Epoch 12/100\n",
      "444/476 [==========================>...] - ETA: 0s - loss: 0.5591 - acc: 0.8514\n",
      "Epoch 00012: val_acc improved from 0.83193 to 0.85714, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 305us/sample - loss: 0.5597 - acc: 0.8466 - val_loss: 0.5517 - val_acc: 0.8571\n",
      "Epoch 13/100\n",
      "380/476 [======================>.......] - ETA: 0s - loss: 0.5493 - acc: 0.8684\n",
      "Epoch 00013: val_acc improved from 0.85714 to 0.87395, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 348us/sample - loss: 0.5455 - acc: 0.8739 - val_loss: 0.5373 - val_acc: 0.8739\n",
      "Epoch 14/100\n",
      "420/476 [=========================>....] - ETA: 0s - loss: 0.5337 - acc: 0.8905\n",
      "Epoch 00014: val_acc improved from 0.87395 to 0.88235, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 311us/sample - loss: 0.5303 - acc: 0.8908 - val_loss: 0.5220 - val_acc: 0.8824\n",
      "Epoch 15/100\n",
      "440/476 [==========================>...] - ETA: 0s - loss: 0.5124 - acc: 0.9045\n",
      "Epoch 00015: val_acc improved from 0.88235 to 0.89076, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 303us/sample - loss: 0.5143 - acc: 0.9013 - val_loss: 0.5058 - val_acc: 0.8908\n",
      "Epoch 16/100\n",
      "376/476 [======================>.......] - ETA: 0s - loss: 0.4991 - acc: 0.9202\n",
      "Epoch 00016: val_acc improved from 0.89076 to 0.89916, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 360us/sample - loss: 0.4973 - acc: 0.9181 - val_loss: 0.4887 - val_acc: 0.8992\n",
      "Epoch 17/100\n",
      "408/476 [========================>.....] - ETA: 0s - loss: 0.4819 - acc: 0.9265\n",
      "Epoch 00017: val_acc improved from 0.89916 to 0.90756, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 323us/sample - loss: 0.4796 - acc: 0.9307 - val_loss: 0.4709 - val_acc: 0.9076\n",
      "Epoch 18/100\n",
      "416/476 [=========================>....] - ETA: 0s - loss: 0.4595 - acc: 0.9351\n",
      "Epoch 00018: val_acc improved from 0.90756 to 0.92437, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 326us/sample - loss: 0.4613 - acc: 0.9328 - val_loss: 0.4525 - val_acc: 0.9244\n",
      "Epoch 19/100\n",
      "368/476 [======================>.......] - ETA: 0s - loss: 0.4427 - acc: 0.9402\n",
      "Epoch 00019: val_acc improved from 0.92437 to 0.93277, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 332us/sample - loss: 0.4423 - acc: 0.9412 - val_loss: 0.4334 - val_acc: 0.9328\n",
      "Epoch 20/100\n",
      "432/476 [==========================>...] - ETA: 0s - loss: 0.4268 - acc: 0.9352\n",
      "Epoch 00020: val_acc improved from 0.93277 to 0.94958, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 304us/sample - loss: 0.4228 - acc: 0.9412 - val_loss: 0.4139 - val_acc: 0.9496\n",
      "Epoch 21/100\n",
      "452/476 [===========================>..] - ETA: 0s - loss: 0.4042 - acc: 0.9425\n",
      "Epoch 00021: val_acc did not improve from 0.94958\n",
      "476/476 [==============================] - 0s 264us/sample - loss: 0.4031 - acc: 0.9454 - val_loss: 0.3940 - val_acc: 0.9496\n",
      "Epoch 22/100\n",
      "272/476 [================>.............] - ETA: 0s - loss: 0.3837 - acc: 0.9485\n",
      "Epoch 00022: val_acc improved from 0.94958 to 0.95798, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 248us/sample - loss: 0.3830 - acc: 0.9475 - val_loss: 0.3741 - val_acc: 0.9580\n",
      "Epoch 23/100\n",
      "228/476 [=============>................] - ETA: 0s - loss: 0.3839 - acc: 0.9298\n",
      "Epoch 00023: val_acc did not improve from 0.95798\n",
      "476/476 [==============================] - 0s 245us/sample - loss: 0.3631 - acc: 0.9517 - val_loss: 0.3544 - val_acc: 0.9580\n",
      "Epoch 24/100\n",
      "440/476 [==========================>...] - ETA: 0s - loss: 0.3438 - acc: 0.9523\n",
      "Epoch 00024: val_acc did not improve from 0.95798\n",
      "476/476 [==============================] - 0s 279us/sample - loss: 0.3436 - acc: 0.9538 - val_loss: 0.3350 - val_acc: 0.9580\n",
      "Epoch 25/100\n",
      "400/476 [========================>.....] - ETA: 0s - loss: 0.3255 - acc: 0.9525\n",
      "Epoch 00025: val_acc did not improve from 0.95798\n",
      "476/476 [==============================] - 0s 307us/sample - loss: 0.3244 - acc: 0.9538 - val_loss: 0.3161 - val_acc: 0.9580\n",
      "Epoch 26/100\n",
      "448/476 [===========================>..] - ETA: 0s - loss: 0.3043 - acc: 0.9598\n",
      "Epoch 00026: val_acc improved from 0.95798 to 0.96639, saving model to model_1.h5\n",
      "476/476 [==============================] - 0s 294us/sample - loss: 0.3061 - acc: 0.9559 - val_loss: 0.2980 - val_acc: 0.9664\n",
      "Epoch 27/100\n",
      "472/476 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.9555\n",
      "Epoch 00027: val_acc did not improve from 0.96639\n",
      "476/476 [==============================] - 0s 260us/sample - loss: 0.2885 - acc: 0.9559 - val_loss: 0.2807 - val_acc: 0.9664\n",
      "Epoch 28/100\n",
      "448/476 [===========================>..] - ETA: 0s - loss: 0.2751 - acc: 0.9531\n",
      "Epoch 00028: val_acc did not improve from 0.96639\n",
      "476/476 [==============================] - 0s 263us/sample - loss: 0.2720 - acc: 0.9559 - val_loss: 0.2645 - val_acc: 0.9664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "448/476 [===========================>..] - ETA: 0s - loss: 0.2583 - acc: 0.9598\n",
      "Epoch 00029: val_acc did not improve from 0.96639\n",
      "476/476 [==============================] - 0s 272us/sample - loss: 0.2566 - acc: 0.9601 - val_loss: 0.2492 - val_acc: 0.9664\n",
      "Epoch 30/100\n",
      "436/476 [==========================>...] - ETA: 0s - loss: 0.2402 - acc: 0.9633\n",
      "Epoch 00030: val_acc did not improve from 0.96639\n",
      "476/476 [==============================] - 0s 274us/sample - loss: 0.2423 - acc: 0.9601 - val_loss: 0.2352 - val_acc: 0.9664\n",
      "Epoch 31/100\n",
      "240/476 [==============>...............] - ETA: 0s - loss: 0.2274 - acc: 0.9625\n",
      "Epoch 00031: val_acc did not improve from 0.96639\n",
      "476/476 [==============================] - 0s 253us/sample - loss: 0.2291 - acc: 0.9643 - val_loss: 0.2221 - val_acc: 0.9664\n",
      "Epoch 32/100\n",
      "240/476 [==============>...............] - ETA: 0s - loss: 0.2176 - acc: 0.9708\n",
      "Epoch 00032: val_acc did not improve from 0.96639\n",
      "476/476 [==============================] - 0s 253us/sample - loss: 0.2171 - acc: 0.9643 - val_loss: 0.2102 - val_acc: 0.9664\n",
      "Epoch 33/100\n",
      "392/476 [=======================>......] - ETA: 0s - loss: 0.2039 - acc: 0.9694\n",
      "Epoch 00033: val_acc did not improve from 0.96639\n",
      "476/476 [==============================] - 0s 306us/sample - loss: 0.2061 - acc: 0.9664 - val_loss: 0.1993 - val_acc: 0.9664\n",
      "Epoch 34/100\n",
      "432/476 [==========================>...] - ETA: 0s - loss: 0.2008 - acc: 0.9630\n",
      "Epoch 00034: val_acc did not improve from 0.96639\n",
      "476/476 [==============================] - 0s 283us/sample - loss: 0.1961 - acc: 0.9664 - val_loss: 0.1892 - val_acc: 0.9664\n",
      "Epoch 35/100\n",
      "432/476 [==========================>...] - ETA: 0s - loss: 0.1820 - acc: 0.9699\n",
      "Epoch 00035: val_acc did not improve from 0.96639\n",
      "476/476 [==============================] - 0s 281us/sample - loss: 0.1871 - acc: 0.9664 - val_loss: 0.1804 - val_acc: 0.9664\n",
      "Epoch 36/100\n",
      "448/476 [===========================>..] - ETA: 0s - loss: 0.1793 - acc: 0.9665\n",
      "Epoch 00036: val_acc did not improve from 0.96639\n",
      "476/476 [==============================] - 0s 266us/sample - loss: 0.1789 - acc: 0.9664 - val_loss: 0.1723 - val_acc: 0.9664\n",
      "Epoch 00036: early stopping\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_fwf('data/entradasclassteste.txt', sep=\" \", header=None)\n",
    "\n",
    "#print(data_test.isnull().sum())\n",
    "\n",
    "def fillWithMean(df):\n",
    "  return df.fillna(df.mean()).dropna(axis=1, how='all') # funcao muito boa para remover outlier e jogar pra media da coluna\n",
    "\n",
    "data_test=fillWithMean(data_test)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = data_test.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "data_test = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "data_test = np.array(data_test, dtype=\"float\") \n",
    "\n",
    "\n",
    "saida_final=model.predict_classes(data_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('RODRIGO_CUPERTINO_saidateste.txt', 'w') as f:\n",
    "    csv.writer(f, delimiter=' ').writerows(saida_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_fwf('data/entradasclassteste.txt', sep=\" \", header=None)\n",
    "print(len(data_test))\n",
    "len(saida_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import initializers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def scale_nn(X_nn, y_nn):\n",
    "    '''Scale data to fit Keras NN input format'''\n",
    "    \n",
    "    #Import Scaler to standardize variable data\n",
    "    scaler = StandardScaler()\n",
    "    X_nn = scaler.fit_transform(X_nn)\n",
    "    \n",
    "    #Use keras utils to format target data\n",
    "    y_nn = np_utils.to_categorical(y_nn)\n",
    "    \n",
    "    return X_nn, y_nn\n",
    "    \n",
    "    \n",
    "def build_nn(X_nn, y_nn, input_dim):\n",
    "    '''Build your Neural Network structure'''\n",
    "    \n",
    "    # Train test split your data to prevent over fitting\n",
    "    X_nn_train, X_nn_test, y_nn_train, y_nn_test = train_test_split(X_nn, y_nn)\n",
    "    \n",
    "    # Initialize your sequential NN\n",
    "    # You can change the model to something other than sequential, for more info check Keras' documentation.\n",
    "    model = Sequential()\n",
    "    \n",
    "    # This part adds the number of perceptrons you would like to use in the first layer\n",
    "    # The input dimension is the number of variables you have in your data\n",
    "    # The activation parameter is what kind of function you to use for your perceptron function\n",
    "    # You can use a variety of different perceptron functions but relu is very common\n",
    "    model.add(Dense(300, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "    \n",
    "    # Build the second layer of your neural network\n",
    "    model.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
    "    \n",
    "    # The last layer is your output layer so the number of perceptions must be equal to the \n",
    "    # amount target classes your data set has.\n",
    "    # Softmax is a good function for binary data, but for more information check the Keras\n",
    "    # documentation.\n",
    "    model.add(Dense(y_nn_test.shape[1], kernel_initializer='normal', activation='softmax'))\n",
    "    \n",
    "    # Lastly you want to define your loss function, your optimizer and your metric for scoring.\n",
    "    # This will vary based on your goals, but for a binary target this parameter configuration\n",
    "    # works well. \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Return your neural network\n",
    "    return model\n",
    "def run_nn(X_nn, y_nn, num_folds):\n",
    "    '''Run your neural network and output your prediction probabilities'''\n",
    "    \n",
    "    # Initialize the roc-auc score running average list\n",
    "    # Initialize a count to print the number of folds\n",
    "    av_roc = 0.\n",
    "    count = 0\n",
    "    \n",
    "    # Run the standard scaler function we defined before\n",
    "    X_nn, y_nn = scale_nn(X_nn, y_nn)\n",
    "    \n",
    "    # Initialize your cross vailidation\n",
    "    # Set shuffle equals True to randomize your splits on your training data\n",
    "    kf = KFold(n_splits=num_folds, random_state=41, shuffle=True)\n",
    "    \n",
    "    # Set up for loop to run for the number of cross vals you defined in your parameter\n",
    "    for train_index, test_index in kf.split(X_nn):\n",
    "        count += 1\n",
    "        print ('Fold #: ', count)\n",
    "        \n",
    "        # This indexs your train and test data for your cross validation and sorts them\n",
    "        # in random order, since we used shuffle equals True\n",
    "        X_nn_train, X_nn_test = X_nn[train_index], X_nn[test_index]\n",
    "        y_nn_train, y_nn_test = y_nn[train_index], y_nn[test_index]\n",
    "        \n",
    "        # Define your input dimension, which must equal the number of variables in your\n",
    "        # training data. If it does not you will get a goofy error.\n",
    "        input_dim = X_nn_train.shape[1]\n",
    "        \n",
    "        # Initialize your neural network structure we defined above to build your model\n",
    "        print(\"Building model...\")\n",
    "        model = build_nn(X_nn, y_nn, input_dim)\n",
    "        \n",
    "        # Fit your model\n",
    "        # You can select the number of epochs and and batch size you would like to use\n",
    "        # for your neural network. \n",
    "        print(\"Training model...\")\n",
    "        model.fit(X_nn_train, y_nn_train, epochs=15, batch_size=30, verbose=0)\n",
    "        \n",
    "        # Your model is fit. Time to predict our output and test our training data\n",
    "        print(\"Evaluating model...\")\n",
    "        test_preds = model.predict_proba(X_nn_test, verbose=0)\n",
    "        roc = roc_auc_score(y_nn_test, test_preds)\n",
    "        scores = model.evaluate(X_nn_test, y_nn_test)\n",
    "        print (scores)\n",
    "        \n",
    "        # Print your model summary\n",
    "        print (model.summary())\n",
    "        \n",
    "        # Print your ROC-AUC score for your kfold, and the running score average\n",
    "        print ('ROC: ', roc)\n",
    "        av_roc += roc\n",
    "        print ('Continued Avg: ', av_roc/count)\n",
    "# Print your final average ROC-AUC score and organize your models predictions in a dataframe\n",
    "    print('Average ROC:', av_roc/num_folds)\n",
    "    predict_proba_all = pd.DataFrame(model.predict_proba(X_nn, verbose=0))\n",
    "    return pd.DataFrame(predict_proba_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #:  1\n",
      "Building model...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "[0.09508724510669708, 0.9666666388511658]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 300)               3000      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 93,902\n",
      "Trainable params: 93,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "ROC:  1.0\n",
      "Continued Avg:  1.0\n",
      "Fold #:  2\n",
      "Building model...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "[0.1793402135372162, 0.8999999761581421]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 300)               3000      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 93,902\n",
      "Trainable params: 93,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "ROC:  1.0\n",
      "Continued Avg:  1.0\n",
      "Fold #:  3\n",
      "Building model...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "[0.19460853934288025, 0.9666666388511658]\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 300)               3000      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 93,902\n",
      "Trainable params: 93,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "ROC:  0.9937888198757765\n",
      "Continued Avg:  0.9979296066252589\n",
      "Fold #:  4\n",
      "Building model...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "[0.03568067401647568, 0.9655172228813171]\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 300)               3000      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 93,902\n",
      "Trainable params: 93,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "ROC:  1.0\n",
      "Continued Avg:  0.9984472049689441\n",
      "Average ROC: 0.9984472049689441\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.976055</td>\n",
       "      <td>0.023945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.999440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.999934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.999065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.999858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.999674</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.985370</td>\n",
       "      <td>0.014630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.999934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.998701</td>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.999879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0    0.976055  0.023945\n",
       "1    0.000560  0.999440\n",
       "2    0.000066  0.999934\n",
       "3    0.000935  0.999065\n",
       "4    0.000142  0.999858\n",
       "..        ...       ...\n",
       "114  0.999674  0.000326\n",
       "115  0.985370  0.014630\n",
       "116  0.000066  0.999934\n",
       "117  0.998701  0.001299\n",
       "118  0.000121  0.999879\n",
       "\n",
       "[119 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_nn(testX, testY,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethoflow_env",
   "language": "python",
   "name": "ethoflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
